{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. The task in hand is to identify fraudulent credit card transactions.\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variables\n",
    "\n",
    "Time: Number of seconds elapsed between this transaction and the first transaction in the dataset\n",
    "\n",
    "V1-V28: may be result of a PCA Dimensionality reduction to protect user identities and sensitive features(v1-v28)\n",
    "\n",
    "Amount: Transaction amount\n",
    "\n",
    "### Target Variable\n",
    "\n",
    "Class: 1 for fraudulent transactions, 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all except two of the input variables are uninterpretable, there is not much scope for feature engineering. We are going to compute the difference in time between transactions from the 'Time' variable for some preliminary analysis, but won't be using it as an input in our final model. We will standardize all of the input variables before feeding them to the model. The data will then be divided into train, validation and test sets.\n",
    "\n",
    "To address the large imbalance of classes, we will be using ADASYN (Adaptive Synthetic sampling) to create synthetic data from 10 nearest neighbors of each point of the minority class. As the ratio of imbalance is large, we will be oversampling the minority class to one-tenth of the minority class for training purpose. We will rely on the model 'class_weight' property to handle the reduced imbalance of the dataset.\n",
    "\n",
    "We will be using a Random Forest Classifier, a k-Nearest Neighbor Classifier and a Neural Network-based Classifier as our credit card fraud detector, and will be using the area under precision-recall curve as the metric for measuring model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('.../creditcard.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that the dataset has no missing values, and all input variables are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a savepoint\n",
    "\n",
    "data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This confirms the large imbalance of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
       "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Amount  Class  Time_Diff  \n",
       "0  0.133558 -0.021053  149.62      0        0.0  \n",
       "1 -0.008983  0.014724    2.69      0        0.0  \n",
       "2 -0.055353 -0.059752  378.66      0        1.0  \n",
       "3  0.062723  0.061458  123.50      0        0.0  \n",
       "4  0.219422  0.215153   69.99      0        1.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating variable 'Time_Diff' denoting time difference between transactions\n",
    "\n",
    "data['Time_Diff'] = data.Time.diff()\n",
    "data.loc[0, 'Time_Diff'] = 0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  Time_Diff  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0        0.0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0        0.0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0        1.0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0        0.0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0        1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the 'Time' variable from our data\n",
    "\n",
    "data.drop('Time', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23fc9adabe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data.Class == 1].Time_Diff.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This shows that roughly half the fraudulent transactions occured simultaneously (on the seconds scale) with a non-fraudulent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.Amount == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23fcad93d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data.Amount != 0].Amount.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Time_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.697350e-17</td>\n",
       "      <td>-1.424390e-15</td>\n",
       "      <td>1.755316e-17</td>\n",
       "      <td>6.391162e-17</td>\n",
       "      <td>2.398071e-16</td>\n",
       "      <td>1.991550e-15</td>\n",
       "      <td>-9.490675e-17</td>\n",
       "      <td>2.169581e-16</td>\n",
       "      <td>7.433820e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.755072e-16</td>\n",
       "      <td>7.477367e-17</td>\n",
       "      <td>9.808705e-16</td>\n",
       "      <td>7.354269e-17</td>\n",
       "      <td>-9.805358e-16</td>\n",
       "      <td>-8.621897e-17</td>\n",
       "      <td>3.208233e-17</td>\n",
       "      <td>9.820892e-16</td>\n",
       "      <td>-0.227709</td>\n",
       "      <td>-0.008074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>4.697350e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.512175e-16</td>\n",
       "      <td>-1.126388e-16</td>\n",
       "      <td>-2.039868e-16</td>\n",
       "      <td>5.024680e-16</td>\n",
       "      <td>3.966486e-16</td>\n",
       "      <td>-4.413984e-17</td>\n",
       "      <td>-5.728718e-17</td>\n",
       "      <td>-4.782388e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.444409e-17</td>\n",
       "      <td>2.500830e-16</td>\n",
       "      <td>1.059562e-16</td>\n",
       "      <td>-8.142354e-18</td>\n",
       "      <td>-4.261894e-17</td>\n",
       "      <td>2.601622e-16</td>\n",
       "      <td>-4.478472e-16</td>\n",
       "      <td>-3.676415e-16</td>\n",
       "      <td>-0.531409</td>\n",
       "      <td>0.024858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-1.424390e-15</td>\n",
       "      <td>2.512175e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.416910e-16</td>\n",
       "      <td>-1.436514e-15</td>\n",
       "      <td>1.431581e-15</td>\n",
       "      <td>2.168574e-15</td>\n",
       "      <td>3.433113e-16</td>\n",
       "      <td>-4.233770e-16</td>\n",
       "      <td>6.289267e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.971969e-17</td>\n",
       "      <td>4.648259e-16</td>\n",
       "      <td>2.115206e-17</td>\n",
       "      <td>-9.351637e-17</td>\n",
       "      <td>4.771164e-16</td>\n",
       "      <td>6.521501e-16</td>\n",
       "      <td>6.239832e-16</td>\n",
       "      <td>7.726948e-16</td>\n",
       "      <td>-0.210880</td>\n",
       "      <td>0.019989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>1.755316e-17</td>\n",
       "      <td>-1.126388e-16</td>\n",
       "      <td>-3.416910e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.940929e-15</td>\n",
       "      <td>-2.712659e-16</td>\n",
       "      <td>1.556330e-16</td>\n",
       "      <td>5.195643e-16</td>\n",
       "      <td>3.859585e-16</td>\n",
       "      <td>6.055490e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.976950e-17</td>\n",
       "      <td>2.099922e-16</td>\n",
       "      <td>6.002528e-17</td>\n",
       "      <td>2.229738e-16</td>\n",
       "      <td>5.394585e-16</td>\n",
       "      <td>-6.179751e-16</td>\n",
       "      <td>-6.403423e-17</td>\n",
       "      <td>-5.863664e-17</td>\n",
       "      <td>0.098732</td>\n",
       "      <td>0.039772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>6.391162e-17</td>\n",
       "      <td>-2.039868e-16</td>\n",
       "      <td>-1.436514e-15</td>\n",
       "      <td>-1.940929e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.926364e-16</td>\n",
       "      <td>-4.209851e-16</td>\n",
       "      <td>7.589187e-16</td>\n",
       "      <td>4.205206e-16</td>\n",
       "      <td>-6.601716e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.368701e-16</td>\n",
       "      <td>5.060029e-16</td>\n",
       "      <td>1.637596e-16</td>\n",
       "      <td>-9.286095e-16</td>\n",
       "      <td>5.625102e-16</td>\n",
       "      <td>9.144690e-16</td>\n",
       "      <td>4.465960e-16</td>\n",
       "      <td>-3.299167e-16</td>\n",
       "      <td>-0.386356</td>\n",
       "      <td>0.020337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>2.398071e-16</td>\n",
       "      <td>5.024680e-16</td>\n",
       "      <td>1.431581e-15</td>\n",
       "      <td>-2.712659e-16</td>\n",
       "      <td>7.926364e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.429426e-16</td>\n",
       "      <td>-1.707421e-16</td>\n",
       "      <td>1.114447e-16</td>\n",
       "      <td>2.850776e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.575903e-16</td>\n",
       "      <td>-3.362902e-16</td>\n",
       "      <td>-7.232186e-17</td>\n",
       "      <td>-1.261867e-15</td>\n",
       "      <td>1.081933e-15</td>\n",
       "      <td>-2.378414e-16</td>\n",
       "      <td>-2.623818e-16</td>\n",
       "      <td>4.813155e-16</td>\n",
       "      <td>0.215981</td>\n",
       "      <td>0.007611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>1.991550e-15</td>\n",
       "      <td>3.966486e-16</td>\n",
       "      <td>2.168574e-15</td>\n",
       "      <td>1.556330e-16</td>\n",
       "      <td>-4.209851e-16</td>\n",
       "      <td>1.429426e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-8.691834e-17</td>\n",
       "      <td>7.933251e-16</td>\n",
       "      <td>3.043333e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.938604e-16</td>\n",
       "      <td>-1.058131e-15</td>\n",
       "      <td>2.327911e-16</td>\n",
       "      <td>-2.589727e-17</td>\n",
       "      <td>1.174169e-15</td>\n",
       "      <td>-7.334507e-16</td>\n",
       "      <td>-5.886825e-16</td>\n",
       "      <td>-6.836764e-17</td>\n",
       "      <td>0.397311</td>\n",
       "      <td>-0.002922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-9.490675e-17</td>\n",
       "      <td>-4.413984e-17</td>\n",
       "      <td>3.433113e-16</td>\n",
       "      <td>5.195643e-16</td>\n",
       "      <td>7.589187e-16</td>\n",
       "      <td>-1.707421e-16</td>\n",
       "      <td>-8.691834e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.900829e-16</td>\n",
       "      <td>9.051847e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.412439e-16</td>\n",
       "      <td>5.475559e-16</td>\n",
       "      <td>3.897104e-16</td>\n",
       "      <td>-1.802967e-16</td>\n",
       "      <td>-1.390791e-16</td>\n",
       "      <td>-1.209975e-16</td>\n",
       "      <td>1.733633e-16</td>\n",
       "      <td>-4.484325e-16</td>\n",
       "      <td>-0.103079</td>\n",
       "      <td>-0.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>2.169581e-16</td>\n",
       "      <td>-5.728718e-17</td>\n",
       "      <td>-4.233770e-16</td>\n",
       "      <td>3.859585e-16</td>\n",
       "      <td>4.205206e-16</td>\n",
       "      <td>1.114447e-16</td>\n",
       "      <td>7.933251e-16</td>\n",
       "      <td>2.900829e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.771761e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>4.578389e-17</td>\n",
       "      <td>2.871855e-17</td>\n",
       "      <td>5.929286e-16</td>\n",
       "      <td>-2.346385e-16</td>\n",
       "      <td>1.099645e-15</td>\n",
       "      <td>-1.388725e-15</td>\n",
       "      <td>-2.287414e-16</td>\n",
       "      <td>9.146779e-16</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>0.144383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>7.433820e-17</td>\n",
       "      <td>-4.782388e-16</td>\n",
       "      <td>6.289267e-16</td>\n",
       "      <td>6.055490e-16</td>\n",
       "      <td>-6.601716e-16</td>\n",
       "      <td>2.850776e-16</td>\n",
       "      <td>3.043333e-17</td>\n",
       "      <td>9.051847e-17</td>\n",
       "      <td>-2.771761e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.089504e-16</td>\n",
       "      <td>-6.707598e-16</td>\n",
       "      <td>3.809732e-16</td>\n",
       "      <td>-4.032806e-17</td>\n",
       "      <td>-2.863813e-16</td>\n",
       "      <td>-2.554293e-16</td>\n",
       "      <td>-3.103239e-16</td>\n",
       "      <td>-1.515934e-16</td>\n",
       "      <td>-0.101502</td>\n",
       "      <td>-0.045864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>2.438580e-16</td>\n",
       "      <td>9.468995e-16</td>\n",
       "      <td>-5.501758e-17</td>\n",
       "      <td>-2.083600e-16</td>\n",
       "      <td>7.342759e-16</td>\n",
       "      <td>4.865799e-16</td>\n",
       "      <td>-1.084105e-15</td>\n",
       "      <td>1.954747e-16</td>\n",
       "      <td>4.682341e-16</td>\n",
       "      <td>2.624448e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.911893e-16</td>\n",
       "      <td>-3.811640e-17</td>\n",
       "      <td>2.232007e-16</td>\n",
       "      <td>1.219849e-15</td>\n",
       "      <td>-4.567635e-16</td>\n",
       "      <td>-1.110976e-16</td>\n",
       "      <td>-2.635827e-16</td>\n",
       "      <td>-3.091914e-16</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.096411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>2.422086e-16</td>\n",
       "      <td>-6.588252e-16</td>\n",
       "      <td>2.206522e-16</td>\n",
       "      <td>-5.657963e-16</td>\n",
       "      <td>3.761033e-16</td>\n",
       "      <td>2.140589e-16</td>\n",
       "      <td>1.510045e-15</td>\n",
       "      <td>-6.266057e-17</td>\n",
       "      <td>-2.445230e-15</td>\n",
       "      <td>1.439907e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.229576e-16</td>\n",
       "      <td>-5.903992e-16</td>\n",
       "      <td>1.392162e-16</td>\n",
       "      <td>4.901644e-16</td>\n",
       "      <td>5.053736e-16</td>\n",
       "      <td>-5.759321e-16</td>\n",
       "      <td>-2.312619e-16</td>\n",
       "      <td>7.327446e-16</td>\n",
       "      <td>-0.009542</td>\n",
       "      <td>-0.256820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-2.115458e-16</td>\n",
       "      <td>3.854521e-16</td>\n",
       "      <td>-6.883375e-16</td>\n",
       "      <td>-1.506129e-16</td>\n",
       "      <td>-9.578659e-16</td>\n",
       "      <td>-2.268061e-16</td>\n",
       "      <td>-9.892325e-17</td>\n",
       "      <td>-2.382948e-16</td>\n",
       "      <td>-2.650351e-16</td>\n",
       "      <td>-8.853582e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>9.499130e-17</td>\n",
       "      <td>-2.659710e-17</td>\n",
       "      <td>-5.884304e-16</td>\n",
       "      <td>-5.470547e-16</td>\n",
       "      <td>8.066738e-17</td>\n",
       "      <td>-2.121518e-16</td>\n",
       "      <td>-4.520414e-16</td>\n",
       "      <td>1.049541e-15</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.169278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>9.352582e-16</td>\n",
       "      <td>-2.541036e-16</td>\n",
       "      <td>4.271336e-16</td>\n",
       "      <td>-8.522435e-17</td>\n",
       "      <td>-3.634803e-16</td>\n",
       "      <td>3.452801e-16</td>\n",
       "      <td>-1.729462e-16</td>\n",
       "      <td>-1.131098e-16</td>\n",
       "      <td>2.343317e-16</td>\n",
       "      <td>2.622513e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.634141e-17</td>\n",
       "      <td>3.439699e-16</td>\n",
       "      <td>7.620728e-17</td>\n",
       "      <td>2.335749e-16</td>\n",
       "      <td>-2.606783e-16</td>\n",
       "      <td>-6.580254e-18</td>\n",
       "      <td>1.285770e-16</td>\n",
       "      <td>2.503271e-15</td>\n",
       "      <td>0.033751</td>\n",
       "      <td>0.136038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-3.252451e-16</td>\n",
       "      <td>2.831060e-16</td>\n",
       "      <td>1.122756e-16</td>\n",
       "      <td>-1.507718e-16</td>\n",
       "      <td>-5.132620e-16</td>\n",
       "      <td>-6.368111e-18</td>\n",
       "      <td>1.936832e-17</td>\n",
       "      <td>2.021491e-16</td>\n",
       "      <td>-1.588105e-15</td>\n",
       "      <td>7.615272e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947458e-17</td>\n",
       "      <td>-8.936817e-16</td>\n",
       "      <td>1.119827e-16</td>\n",
       "      <td>-4.589689e-16</td>\n",
       "      <td>3.869740e-16</td>\n",
       "      <td>3.761094e-16</td>\n",
       "      <td>-1.265235e-15</td>\n",
       "      <td>-1.063286e-15</td>\n",
       "      <td>-0.002986</td>\n",
       "      <td>-0.072427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>6.308789e-16</td>\n",
       "      <td>4.934097e-17</td>\n",
       "      <td>1.183364e-15</td>\n",
       "      <td>-6.939204e-16</td>\n",
       "      <td>-3.517076e-16</td>\n",
       "      <td>-2.477917e-16</td>\n",
       "      <td>2.893672e-16</td>\n",
       "      <td>5.027192e-16</td>\n",
       "      <td>-3.251906e-16</td>\n",
       "      <td>-1.705923e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.927401e-16</td>\n",
       "      <td>3.878384e-17</td>\n",
       "      <td>8.519670e-16</td>\n",
       "      <td>-4.289239e-16</td>\n",
       "      <td>-6.644104e-16</td>\n",
       "      <td>-5.186503e-16</td>\n",
       "      <td>7.820038e-16</td>\n",
       "      <td>8.637186e-16</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>-0.015441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-5.011524e-16</td>\n",
       "      <td>-9.883008e-16</td>\n",
       "      <td>4.576619e-17</td>\n",
       "      <td>-4.397925e-16</td>\n",
       "      <td>1.425729e-16</td>\n",
       "      <td>3.567582e-16</td>\n",
       "      <td>1.149692e-15</td>\n",
       "      <td>-3.508777e-16</td>\n",
       "      <td>6.535992e-16</td>\n",
       "      <td>3.674182e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.753967e-16</td>\n",
       "      <td>-8.389703e-16</td>\n",
       "      <td>5.367784e-16</td>\n",
       "      <td>-5.543631e-17</td>\n",
       "      <td>4.822068e-16</td>\n",
       "      <td>4.870302e-16</td>\n",
       "      <td>8.844373e-16</td>\n",
       "      <td>-2.182692e-16</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.066686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>2.870125e-16</td>\n",
       "      <td>2.636654e-16</td>\n",
       "      <td>5.427965e-16</td>\n",
       "      <td>1.493667e-16</td>\n",
       "      <td>1.109525e-15</td>\n",
       "      <td>2.811474e-16</td>\n",
       "      <td>-1.116789e-16</td>\n",
       "      <td>-4.093852e-16</td>\n",
       "      <td>1.203843e-16</td>\n",
       "      <td>3.986710e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.140973e-15</td>\n",
       "      <td>-8.662635e-17</td>\n",
       "      <td>-3.624236e-16</td>\n",
       "      <td>-1.126043e-16</td>\n",
       "      <td>-2.310856e-16</td>\n",
       "      <td>3.183964e-16</td>\n",
       "      <td>2.435170e-16</td>\n",
       "      <td>8.844995e-16</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.025358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>1.818128e-16</td>\n",
       "      <td>9.528280e-17</td>\n",
       "      <td>2.576773e-16</td>\n",
       "      <td>-2.656938e-16</td>\n",
       "      <td>-3.138234e-16</td>\n",
       "      <td>2.717167e-16</td>\n",
       "      <td>-2.874017e-16</td>\n",
       "      <td>-5.339821e-16</td>\n",
       "      <td>1.120752e-16</td>\n",
       "      <td>2.663038e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.032541e-16</td>\n",
       "      <td>-9.690436e-16</td>\n",
       "      <td>5.733798e-16</td>\n",
       "      <td>3.126716e-17</td>\n",
       "      <td>7.415355e-16</td>\n",
       "      <td>5.614354e-16</td>\n",
       "      <td>-1.113035e-16</td>\n",
       "      <td>-1.375843e-15</td>\n",
       "      <td>-0.056151</td>\n",
       "      <td>-0.025921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>1.036959e-16</td>\n",
       "      <td>-9.309954e-16</td>\n",
       "      <td>-9.429297e-16</td>\n",
       "      <td>-3.223123e-16</td>\n",
       "      <td>2.076048e-16</td>\n",
       "      <td>1.898638e-16</td>\n",
       "      <td>1.744242e-16</td>\n",
       "      <td>-1.095534e-16</td>\n",
       "      <td>-4.340941e-16</td>\n",
       "      <td>-1.141888e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.120828e-15</td>\n",
       "      <td>1.105842e-15</td>\n",
       "      <td>4.986739e-16</td>\n",
       "      <td>1.637488e-16</td>\n",
       "      <td>-1.518242e-16</td>\n",
       "      <td>-2.975081e-16</td>\n",
       "      <td>-1.446069e-15</td>\n",
       "      <td>-1.133579e-16</td>\n",
       "      <td>0.339403</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>-1.755072e-16</td>\n",
       "      <td>8.444409e-17</td>\n",
       "      <td>-2.971969e-17</td>\n",
       "      <td>-9.976950e-17</td>\n",
       "      <td>-1.368701e-16</td>\n",
       "      <td>-1.575903e-16</td>\n",
       "      <td>1.938604e-16</td>\n",
       "      <td>-2.412439e-16</td>\n",
       "      <td>4.578389e-17</td>\n",
       "      <td>8.089504e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.905948e-15</td>\n",
       "      <td>6.127323e-16</td>\n",
       "      <td>1.298254e-16</td>\n",
       "      <td>-2.826293e-16</td>\n",
       "      <td>-4.907301e-16</td>\n",
       "      <td>-1.033403e-15</td>\n",
       "      <td>5.132234e-16</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>-0.011340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>7.477367e-17</td>\n",
       "      <td>2.500830e-16</td>\n",
       "      <td>4.648259e-16</td>\n",
       "      <td>2.099922e-16</td>\n",
       "      <td>5.060029e-16</td>\n",
       "      <td>-3.362902e-16</td>\n",
       "      <td>-1.058131e-15</td>\n",
       "      <td>5.475559e-16</td>\n",
       "      <td>2.871855e-17</td>\n",
       "      <td>-6.707598e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.905948e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.130812e-16</td>\n",
       "      <td>1.150829e-17</td>\n",
       "      <td>-6.078986e-16</td>\n",
       "      <td>-8.477050e-16</td>\n",
       "      <td>-1.294910e-16</td>\n",
       "      <td>-3.021376e-16</td>\n",
       "      <td>-0.064801</td>\n",
       "      <td>-0.017452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>9.808705e-16</td>\n",
       "      <td>1.059562e-16</td>\n",
       "      <td>2.115206e-17</td>\n",
       "      <td>6.002528e-17</td>\n",
       "      <td>1.637596e-16</td>\n",
       "      <td>-7.232186e-17</td>\n",
       "      <td>2.327911e-16</td>\n",
       "      <td>3.897104e-16</td>\n",
       "      <td>5.929286e-16</td>\n",
       "      <td>3.809732e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>6.127323e-16</td>\n",
       "      <td>3.130812e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-4.411271e-17</td>\n",
       "      <td>-9.938362e-16</td>\n",
       "      <td>8.848700e-16</td>\n",
       "      <td>5.524044e-16</td>\n",
       "      <td>9.029821e-16</td>\n",
       "      <td>-0.112633</td>\n",
       "      <td>-0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>7.354269e-17</td>\n",
       "      <td>-8.142354e-18</td>\n",
       "      <td>-9.351637e-17</td>\n",
       "      <td>2.229738e-16</td>\n",
       "      <td>-9.286095e-16</td>\n",
       "      <td>-1.261867e-15</td>\n",
       "      <td>-2.589727e-17</td>\n",
       "      <td>-1.802967e-16</td>\n",
       "      <td>-2.346385e-16</td>\n",
       "      <td>-4.032806e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.298254e-16</td>\n",
       "      <td>1.150829e-17</td>\n",
       "      <td>-4.411271e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.557318e-15</td>\n",
       "      <td>3.129195e-16</td>\n",
       "      <td>-3.736529e-16</td>\n",
       "      <td>-2.259275e-16</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>-0.005747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-9.805358e-16</td>\n",
       "      <td>-4.261894e-17</td>\n",
       "      <td>4.771164e-16</td>\n",
       "      <td>5.394585e-16</td>\n",
       "      <td>5.625102e-16</td>\n",
       "      <td>1.081933e-15</td>\n",
       "      <td>1.174169e-15</td>\n",
       "      <td>-1.390791e-16</td>\n",
       "      <td>1.099645e-15</td>\n",
       "      <td>-2.863813e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.826293e-16</td>\n",
       "      <td>-6.078986e-16</td>\n",
       "      <td>-9.938362e-16</td>\n",
       "      <td>1.557318e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.810884e-15</td>\n",
       "      <td>-6.107118e-16</td>\n",
       "      <td>3.399375e-16</td>\n",
       "      <td>-0.047837</td>\n",
       "      <td>-0.003833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-8.621897e-17</td>\n",
       "      <td>2.601622e-16</td>\n",
       "      <td>6.521501e-16</td>\n",
       "      <td>-6.179751e-16</td>\n",
       "      <td>9.144690e-16</td>\n",
       "      <td>-2.378414e-16</td>\n",
       "      <td>-7.334507e-16</td>\n",
       "      <td>-1.209975e-16</td>\n",
       "      <td>-1.388725e-15</td>\n",
       "      <td>-2.554293e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.907301e-16</td>\n",
       "      <td>-8.477050e-16</td>\n",
       "      <td>8.848700e-16</td>\n",
       "      <td>3.129195e-16</td>\n",
       "      <td>2.810884e-15</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.383861e-16</td>\n",
       "      <td>-3.751403e-16</td>\n",
       "      <td>-0.003208</td>\n",
       "      <td>-0.002941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>3.208233e-17</td>\n",
       "      <td>-4.478472e-16</td>\n",
       "      <td>6.239832e-16</td>\n",
       "      <td>-6.403423e-17</td>\n",
       "      <td>4.465960e-16</td>\n",
       "      <td>-2.623818e-16</td>\n",
       "      <td>-5.886825e-16</td>\n",
       "      <td>1.733633e-16</td>\n",
       "      <td>-2.287414e-16</td>\n",
       "      <td>-3.103239e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033403e-15</td>\n",
       "      <td>-1.294910e-16</td>\n",
       "      <td>5.524044e-16</td>\n",
       "      <td>-3.736529e-16</td>\n",
       "      <td>-6.107118e-16</td>\n",
       "      <td>-3.383861e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-3.770124e-16</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>9.820892e-16</td>\n",
       "      <td>-3.676415e-16</td>\n",
       "      <td>7.726948e-16</td>\n",
       "      <td>-5.863664e-17</td>\n",
       "      <td>-3.299167e-16</td>\n",
       "      <td>4.813155e-16</td>\n",
       "      <td>-6.836764e-17</td>\n",
       "      <td>-4.484325e-16</td>\n",
       "      <td>9.146779e-16</td>\n",
       "      <td>-1.515934e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>5.132234e-16</td>\n",
       "      <td>-3.021376e-16</td>\n",
       "      <td>9.029821e-16</td>\n",
       "      <td>-2.259275e-16</td>\n",
       "      <td>3.399375e-16</td>\n",
       "      <td>-3.751403e-16</td>\n",
       "      <td>-3.770124e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-2.277087e-01</td>\n",
       "      <td>-5.314089e-01</td>\n",
       "      <td>-2.108805e-01</td>\n",
       "      <td>9.873167e-02</td>\n",
       "      <td>-3.863563e-01</td>\n",
       "      <td>2.159812e-01</td>\n",
       "      <td>3.973113e-01</td>\n",
       "      <td>-1.030791e-01</td>\n",
       "      <td>-4.424560e-02</td>\n",
       "      <td>-1.015021e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.059989e-01</td>\n",
       "      <td>-6.480065e-02</td>\n",
       "      <td>-1.126326e-01</td>\n",
       "      <td>5.146217e-03</td>\n",
       "      <td>-4.783686e-02</td>\n",
       "      <td>-3.208037e-03</td>\n",
       "      <td>2.882546e-02</td>\n",
       "      <td>1.025822e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_Diff</th>\n",
       "      <td>-8.073963e-03</td>\n",
       "      <td>2.485767e-02</td>\n",
       "      <td>1.998878e-02</td>\n",
       "      <td>3.977233e-02</td>\n",
       "      <td>2.033746e-02</td>\n",
       "      <td>7.610647e-03</td>\n",
       "      <td>-2.921660e-03</td>\n",
       "      <td>-1.140627e-02</td>\n",
       "      <td>1.443831e-01</td>\n",
       "      <td>-4.586367e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.133960e-02</td>\n",
       "      <td>-1.745232e-02</td>\n",
       "      <td>-7.036406e-04</td>\n",
       "      <td>-5.746898e-03</td>\n",
       "      <td>-3.832509e-03</td>\n",
       "      <td>-2.940739e-03</td>\n",
       "      <td>3.577496e-03</td>\n",
       "      <td>2.148194e-03</td>\n",
       "      <td>-0.006227</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     V1            V2            V3            V4  \\\n",
       "V1         1.000000e+00  4.697350e-17 -1.424390e-15  1.755316e-17   \n",
       "V2         4.697350e-17  1.000000e+00  2.512175e-16 -1.126388e-16   \n",
       "V3        -1.424390e-15  2.512175e-16  1.000000e+00 -3.416910e-16   \n",
       "V4         1.755316e-17 -1.126388e-16 -3.416910e-16  1.000000e+00   \n",
       "V5         6.391162e-17 -2.039868e-16 -1.436514e-15 -1.940929e-15   \n",
       "V6         2.398071e-16  5.024680e-16  1.431581e-15 -2.712659e-16   \n",
       "V7         1.991550e-15  3.966486e-16  2.168574e-15  1.556330e-16   \n",
       "V8        -9.490675e-17 -4.413984e-17  3.433113e-16  5.195643e-16   \n",
       "V9         2.169581e-16 -5.728718e-17 -4.233770e-16  3.859585e-16   \n",
       "V10        7.433820e-17 -4.782388e-16  6.289267e-16  6.055490e-16   \n",
       "V11        2.438580e-16  9.468995e-16 -5.501758e-17 -2.083600e-16   \n",
       "V12        2.422086e-16 -6.588252e-16  2.206522e-16 -5.657963e-16   \n",
       "V13       -2.115458e-16  3.854521e-16 -6.883375e-16 -1.506129e-16   \n",
       "V14        9.352582e-16 -2.541036e-16  4.271336e-16 -8.522435e-17   \n",
       "V15       -3.252451e-16  2.831060e-16  1.122756e-16 -1.507718e-16   \n",
       "V16        6.308789e-16  4.934097e-17  1.183364e-15 -6.939204e-16   \n",
       "V17       -5.011524e-16 -9.883008e-16  4.576619e-17 -4.397925e-16   \n",
       "V18        2.870125e-16  2.636654e-16  5.427965e-16  1.493667e-16   \n",
       "V19        1.818128e-16  9.528280e-17  2.576773e-16 -2.656938e-16   \n",
       "V20        1.036959e-16 -9.309954e-16 -9.429297e-16 -3.223123e-16   \n",
       "V21       -1.755072e-16  8.444409e-17 -2.971969e-17 -9.976950e-17   \n",
       "V22        7.477367e-17  2.500830e-16  4.648259e-16  2.099922e-16   \n",
       "V23        9.808705e-16  1.059562e-16  2.115206e-17  6.002528e-17   \n",
       "V24        7.354269e-17 -8.142354e-18 -9.351637e-17  2.229738e-16   \n",
       "V25       -9.805358e-16 -4.261894e-17  4.771164e-16  5.394585e-16   \n",
       "V26       -8.621897e-17  2.601622e-16  6.521501e-16 -6.179751e-16   \n",
       "V27        3.208233e-17 -4.478472e-16  6.239832e-16 -6.403423e-17   \n",
       "V28        9.820892e-16 -3.676415e-16  7.726948e-16 -5.863664e-17   \n",
       "Amount    -2.277087e-01 -5.314089e-01 -2.108805e-01  9.873167e-02   \n",
       "Time_Diff -8.073963e-03  2.485767e-02  1.998878e-02  3.977233e-02   \n",
       "\n",
       "                     V5            V6            V7            V8  \\\n",
       "V1         6.391162e-17  2.398071e-16  1.991550e-15 -9.490675e-17   \n",
       "V2        -2.039868e-16  5.024680e-16  3.966486e-16 -4.413984e-17   \n",
       "V3        -1.436514e-15  1.431581e-15  2.168574e-15  3.433113e-16   \n",
       "V4        -1.940929e-15 -2.712659e-16  1.556330e-16  5.195643e-16   \n",
       "V5         1.000000e+00  7.926364e-16 -4.209851e-16  7.589187e-16   \n",
       "V6         7.926364e-16  1.000000e+00  1.429426e-16 -1.707421e-16   \n",
       "V7        -4.209851e-16  1.429426e-16  1.000000e+00 -8.691834e-17   \n",
       "V8         7.589187e-16 -1.707421e-16 -8.691834e-17  1.000000e+00   \n",
       "V9         4.205206e-16  1.114447e-16  7.933251e-16  2.900829e-16   \n",
       "V10       -6.601716e-16  2.850776e-16  3.043333e-17  9.051847e-17   \n",
       "V11        7.342759e-16  4.865799e-16 -1.084105e-15  1.954747e-16   \n",
       "V12        3.761033e-16  2.140589e-16  1.510045e-15 -6.266057e-17   \n",
       "V13       -9.578659e-16 -2.268061e-16 -9.892325e-17 -2.382948e-16   \n",
       "V14       -3.634803e-16  3.452801e-16 -1.729462e-16 -1.131098e-16   \n",
       "V15       -5.132620e-16 -6.368111e-18  1.936832e-17  2.021491e-16   \n",
       "V16       -3.517076e-16 -2.477917e-16  2.893672e-16  5.027192e-16   \n",
       "V17        1.425729e-16  3.567582e-16  1.149692e-15 -3.508777e-16   \n",
       "V18        1.109525e-15  2.811474e-16 -1.116789e-16 -4.093852e-16   \n",
       "V19       -3.138234e-16  2.717167e-16 -2.874017e-16 -5.339821e-16   \n",
       "V20        2.076048e-16  1.898638e-16  1.744242e-16 -1.095534e-16   \n",
       "V21       -1.368701e-16 -1.575903e-16  1.938604e-16 -2.412439e-16   \n",
       "V22        5.060029e-16 -3.362902e-16 -1.058131e-15  5.475559e-16   \n",
       "V23        1.637596e-16 -7.232186e-17  2.327911e-16  3.897104e-16   \n",
       "V24       -9.286095e-16 -1.261867e-15 -2.589727e-17 -1.802967e-16   \n",
       "V25        5.625102e-16  1.081933e-15  1.174169e-15 -1.390791e-16   \n",
       "V26        9.144690e-16 -2.378414e-16 -7.334507e-16 -1.209975e-16   \n",
       "V27        4.465960e-16 -2.623818e-16 -5.886825e-16  1.733633e-16   \n",
       "V28       -3.299167e-16  4.813155e-16 -6.836764e-17 -4.484325e-16   \n",
       "Amount    -3.863563e-01  2.159812e-01  3.973113e-01 -1.030791e-01   \n",
       "Time_Diff  2.033746e-02  7.610647e-03 -2.921660e-03 -1.140627e-02   \n",
       "\n",
       "                     V9           V10  ...           V21           V22  \\\n",
       "V1         2.169581e-16  7.433820e-17  ... -1.755072e-16  7.477367e-17   \n",
       "V2        -5.728718e-17 -4.782388e-16  ...  8.444409e-17  2.500830e-16   \n",
       "V3        -4.233770e-16  6.289267e-16  ... -2.971969e-17  4.648259e-16   \n",
       "V4         3.859585e-16  6.055490e-16  ... -9.976950e-17  2.099922e-16   \n",
       "V5         4.205206e-16 -6.601716e-16  ... -1.368701e-16  5.060029e-16   \n",
       "V6         1.114447e-16  2.850776e-16  ... -1.575903e-16 -3.362902e-16   \n",
       "V7         7.933251e-16  3.043333e-17  ...  1.938604e-16 -1.058131e-15   \n",
       "V8         2.900829e-16  9.051847e-17  ... -2.412439e-16  5.475559e-16   \n",
       "V9         1.000000e+00 -2.771761e-16  ...  4.578389e-17  2.871855e-17   \n",
       "V10       -2.771761e-16  1.000000e+00  ...  8.089504e-16 -6.707598e-16   \n",
       "V11        4.682341e-16  2.624448e-16  ... -3.911893e-16 -3.811640e-17   \n",
       "V12       -2.445230e-15  1.439907e-15  ...  3.229576e-16 -5.903992e-16   \n",
       "V13       -2.650351e-16 -8.853582e-16  ...  9.499130e-17 -2.659710e-17   \n",
       "V14        2.343317e-16  2.622513e-16  ...  1.634141e-17  3.439699e-16   \n",
       "V15       -1.588105e-15  7.615272e-16  ...  1.947458e-17 -8.936817e-16   \n",
       "V16       -3.251906e-16 -1.705923e-15  ... -3.927401e-16  3.878384e-17   \n",
       "V17        6.535992e-16  3.674182e-15  ... -7.753967e-16 -8.389703e-16   \n",
       "V18        1.203843e-16  3.986710e-16  ... -1.140973e-15 -8.662635e-17   \n",
       "V19        1.120752e-16  2.663038e-17  ...  4.032541e-16 -9.690436e-16   \n",
       "V20       -4.340941e-16 -1.141888e-15  ... -1.120828e-15  1.105842e-15   \n",
       "V21        4.578389e-17  8.089504e-16  ...  1.000000e+00  3.905948e-15   \n",
       "V22        2.871855e-17 -6.707598e-16  ...  3.905948e-15  1.000000e+00   \n",
       "V23        5.929286e-16  3.809732e-16  ...  6.127323e-16  3.130812e-16   \n",
       "V24       -2.346385e-16 -4.032806e-17  ...  1.298254e-16  1.150829e-17   \n",
       "V25        1.099645e-15 -2.863813e-16  ... -2.826293e-16 -6.078986e-16   \n",
       "V26       -1.388725e-15 -2.554293e-16  ... -4.907301e-16 -8.477050e-16   \n",
       "V27       -2.287414e-16 -3.103239e-16  ... -1.033403e-15 -1.294910e-16   \n",
       "V28        9.146779e-16 -1.515934e-16  ...  5.132234e-16 -3.021376e-16   \n",
       "Amount    -4.424560e-02 -1.015021e-01  ...  1.059989e-01 -6.480065e-02   \n",
       "Time_Diff  1.443831e-01 -4.586367e-02  ... -1.133960e-02 -1.745232e-02   \n",
       "\n",
       "                    V23           V24           V25           V26  \\\n",
       "V1         9.808705e-16  7.354269e-17 -9.805358e-16 -8.621897e-17   \n",
       "V2         1.059562e-16 -8.142354e-18 -4.261894e-17  2.601622e-16   \n",
       "V3         2.115206e-17 -9.351637e-17  4.771164e-16  6.521501e-16   \n",
       "V4         6.002528e-17  2.229738e-16  5.394585e-16 -6.179751e-16   \n",
       "V5         1.637596e-16 -9.286095e-16  5.625102e-16  9.144690e-16   \n",
       "V6        -7.232186e-17 -1.261867e-15  1.081933e-15 -2.378414e-16   \n",
       "V7         2.327911e-16 -2.589727e-17  1.174169e-15 -7.334507e-16   \n",
       "V8         3.897104e-16 -1.802967e-16 -1.390791e-16 -1.209975e-16   \n",
       "V9         5.929286e-16 -2.346385e-16  1.099645e-15 -1.388725e-15   \n",
       "V10        3.809732e-16 -4.032806e-17 -2.863813e-16 -2.554293e-16   \n",
       "V11        2.232007e-16  1.219849e-15 -4.567635e-16 -1.110976e-16   \n",
       "V12        1.392162e-16  4.901644e-16  5.053736e-16 -5.759321e-16   \n",
       "V13       -5.884304e-16 -5.470547e-16  8.066738e-17 -2.121518e-16   \n",
       "V14        7.620728e-17  2.335749e-16 -2.606783e-16 -6.580254e-18   \n",
       "V15        1.119827e-16 -4.589689e-16  3.869740e-16  3.761094e-16   \n",
       "V16        8.519670e-16 -4.289239e-16 -6.644104e-16 -5.186503e-16   \n",
       "V17        5.367784e-16 -5.543631e-17  4.822068e-16  4.870302e-16   \n",
       "V18       -3.624236e-16 -1.126043e-16 -2.310856e-16  3.183964e-16   \n",
       "V19        5.733798e-16  3.126716e-17  7.415355e-16  5.614354e-16   \n",
       "V20        4.986739e-16  1.637488e-16 -1.518242e-16 -2.975081e-16   \n",
       "V21        6.127323e-16  1.298254e-16 -2.826293e-16 -4.907301e-16   \n",
       "V22        3.130812e-16  1.150829e-17 -6.078986e-16 -8.477050e-16   \n",
       "V23        1.000000e+00 -4.411271e-17 -9.938362e-16  8.848700e-16   \n",
       "V24       -4.411271e-17  1.000000e+00  1.557318e-15  3.129195e-16   \n",
       "V25       -9.938362e-16  1.557318e-15  1.000000e+00  2.810884e-15   \n",
       "V26        8.848700e-16  3.129195e-16  2.810884e-15  1.000000e+00   \n",
       "V27        5.524044e-16 -3.736529e-16 -6.107118e-16 -3.383861e-16   \n",
       "V28        9.029821e-16 -2.259275e-16  3.399375e-16 -3.751403e-16   \n",
       "Amount    -1.126326e-01  5.146217e-03 -4.783686e-02 -3.208037e-03   \n",
       "Time_Diff -7.036406e-04 -5.746898e-03 -3.832509e-03 -2.940739e-03   \n",
       "\n",
       "                    V27           V28    Amount  Time_Diff  \n",
       "V1         3.208233e-17  9.820892e-16 -0.227709  -0.008074  \n",
       "V2        -4.478472e-16 -3.676415e-16 -0.531409   0.024858  \n",
       "V3         6.239832e-16  7.726948e-16 -0.210880   0.019989  \n",
       "V4        -6.403423e-17 -5.863664e-17  0.098732   0.039772  \n",
       "V5         4.465960e-16 -3.299167e-16 -0.386356   0.020337  \n",
       "V6        -2.623818e-16  4.813155e-16  0.215981   0.007611  \n",
       "V7        -5.886825e-16 -6.836764e-17  0.397311  -0.002922  \n",
       "V8         1.733633e-16 -4.484325e-16 -0.103079  -0.011406  \n",
       "V9        -2.287414e-16  9.146779e-16 -0.044246   0.144383  \n",
       "V10       -3.103239e-16 -1.515934e-16 -0.101502  -0.045864  \n",
       "V11       -2.635827e-16 -3.091914e-16  0.000104   0.096411  \n",
       "V12       -2.312619e-16  7.327446e-16 -0.009542  -0.256820  \n",
       "V13       -4.520414e-16  1.049541e-15  0.005293   0.169278  \n",
       "V14        1.285770e-16  2.503271e-15  0.033751   0.136038  \n",
       "V15       -1.265235e-15 -1.063286e-15 -0.002986  -0.072427  \n",
       "V16        7.820038e-16  8.637186e-16 -0.003910  -0.015441  \n",
       "V17        8.844373e-16 -2.182692e-16  0.007309   0.066686  \n",
       "V18        2.435170e-16  8.844995e-16  0.035650   0.025358  \n",
       "V19       -1.113035e-16 -1.375843e-15 -0.056151  -0.025921  \n",
       "V20       -1.446069e-15 -1.133579e-16  0.339403   0.001187  \n",
       "V21       -1.033403e-15  5.132234e-16  0.105999  -0.011340  \n",
       "V22       -1.294910e-16 -3.021376e-16 -0.064801  -0.017452  \n",
       "V23        5.524044e-16  9.029821e-16 -0.112633  -0.000704  \n",
       "V24       -3.736529e-16 -2.259275e-16  0.005146  -0.005747  \n",
       "V25       -6.107118e-16  3.399375e-16 -0.047837  -0.003833  \n",
       "V26       -3.383861e-16 -3.751403e-16 -0.003208  -0.002941  \n",
       "V27        1.000000e+00 -3.770124e-16  0.028825   0.003577  \n",
       "V28       -3.770124e-16  1.000000e+00  0.010258   0.002148  \n",
       "Amount     2.882546e-02  1.025822e-02  1.000000  -0.006227  \n",
       "Time_Diff  3.577496e-03  2.148194e-03 -0.006227   1.000000  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation between input variables\n",
    "\n",
    "corr = data.drop(['Class'], axis=1).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for input variables with high correlation\n",
    "\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i, corr.shape[1]):\n",
    "        if np.abs(corr.iloc[i,j] > 0.4) and i!=j:\n",
    "            print(i,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that none of the input variables are highly correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Time_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.694242</td>\n",
       "      <td>-0.044075</td>\n",
       "      <td>1.672773</td>\n",
       "      <td>0.973366</td>\n",
       "      <td>-0.245117</td>\n",
       "      <td>0.347068</td>\n",
       "      <td>0.193679</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.331128</td>\n",
       "      <td>0.083386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>-0.176911</td>\n",
       "      <td>0.110507</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>-0.392170</td>\n",
       "      <td>0.330892</td>\n",
       "      <td>-0.063781</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608496</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>0.109797</td>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.043483</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.071253</td>\n",
       "      <td>-0.232494</td>\n",
       "      <td>-0.153350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.880077</td>\n",
       "      <td>0.162201</td>\n",
       "      <td>-0.561131</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.261069</td>\n",
       "      <td>-0.022256</td>\n",
       "      <td>0.044608</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.693500</td>\n",
       "      <td>-0.811578</td>\n",
       "      <td>1.169468</td>\n",
       "      <td>0.268231</td>\n",
       "      <td>-0.364572</td>\n",
       "      <td>1.351454</td>\n",
       "      <td>0.639776</td>\n",
       "      <td>0.207373</td>\n",
       "      <td>-1.378675</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063358</td>\n",
       "      <td>1.456320</td>\n",
       "      <td>-1.138092</td>\n",
       "      <td>-0.628537</td>\n",
       "      <td>-0.288447</td>\n",
       "      <td>-0.137137</td>\n",
       "      <td>-0.181021</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.112169</td>\n",
       "      <td>1.182516</td>\n",
       "      <td>-0.609727</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.936150</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.316018</td>\n",
       "      <td>-1.262503</td>\n",
       "      <td>-0.050468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>-0.304777</td>\n",
       "      <td>-1.941027</td>\n",
       "      <td>1.241904</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>0.155396</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.591330</td>\n",
       "      <td>0.531541</td>\n",
       "      <td>1.021412</td>\n",
       "      <td>0.284655</td>\n",
       "      <td>-0.295015</td>\n",
       "      <td>0.071999</td>\n",
       "      <td>0.479302</td>\n",
       "      <td>-0.226510</td>\n",
       "      <td>0.744326</td>\n",
       "      <td>0.691625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100011</td>\n",
       "      <td>-0.220123</td>\n",
       "      <td>0.233250</td>\n",
       "      <td>-0.395202</td>\n",
       "      <td>1.041611</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>0.651816</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068  0.193679   \n",
       "1  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820 -0.063700   \n",
       "2 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454  0.639776   \n",
       "3 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150  0.192071   \n",
       "4 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999  0.479302   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.082637  0.331128  0.083386  ...  0.382854 -0.176911  0.110507  0.246585   \n",
       "1  0.071253 -0.232494 -0.153350  ... -0.880077  0.162201 -0.561131  0.320694   \n",
       "2  0.207373 -1.378675  0.190700  ...  1.063358  1.456320 -1.138092 -0.628537   \n",
       "3  0.316018 -1.262503 -0.050468  ...  0.007267 -0.304777 -1.941027  1.241904   \n",
       "4 -0.226510  0.744326  0.691625  ...  1.100011 -0.220123  0.233250 -0.395202   \n",
       "\n",
       "        V26       V27       V28    Amount  Class  Time_Diff  \n",
       "0 -0.392170  0.330892 -0.063781  0.244964      0        0.0  \n",
       "1  0.261069 -0.022256  0.044608 -0.342475      0        0.0  \n",
       "2 -0.288447 -0.137137 -0.181021  1.160686      0        1.0  \n",
       "3 -0.460217  0.155396  0.186189  0.140534      0        0.0  \n",
       "4  1.041611  0.543620  0.651816 -0.073403      0        1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardizing input variables\n",
    "\n",
    "cols_list = list(data.columns)[:-2]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[cols_list] = scaler.fit_transform(data[cols_list])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the input and target variables\n",
    "\n",
    "X = data.drop(['Time_Diff','Class'], axis=1)\n",
    "y = data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing the data into train, validation and test sets\n",
    "\n",
    "X_train, X_valandtest, y_train, y_valandtest = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valandtest, y_valandtest, test_size=0.5, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227453    392] \n",
      " [28434    47] \n",
      " [28428    53]\n"
     ]
    }
   ],
   "source": [
    "# checking class balance in train, validation and test sets.\n",
    "\n",
    "print(np.bincount(y_train),'\\n',np.bincount(y_val),'\\n',np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# oversampling the training set to address class imbalance\n",
    "\n",
    "adasyn = ADASYN(ratio=0.1, n_neighbors=10, random_state=9)\n",
    "X_train_bal, y_train_bal = adasyn.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227453,  22779], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking class balance in training set\n",
    "\n",
    "np.bincount(y_train_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=10,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=10)\n",
    "rfc.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28423    11]\n",
      " [    5    42]] \n",
      "\n",
      "Area under PR curve:  0.8410532763648622 \n",
      "\n",
      "Accuracy:  0.9994382219725431\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_val)\n",
    "y_pred_probs = rfc.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=10,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid={'n_estimators': [10, 25, 50], 'max_depth': [2, 5, 10], 'max_features': [2, 8, 'auto']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='average_precision', verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using grid search to find optimal parameter set with scoring set to 'average_precision'\n",
    "# as it is a close approximation of area under precision-recall curve\n",
    "\n",
    "params = {'n_estimators': [10,25,50], \n",
    "          'max_depth': [2,5,10], \n",
    "          'max_features': [2,8,'auto']}\n",
    "\n",
    "gridsearch = GridSearchCV(rfc, param_grid=params, cv=5, scoring='average_precision', n_jobs=2)\n",
    "gridsearch.fit(X_train_bal,y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=8,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=False, random_state=10,\n",
      "            verbose=0, warm_start=False) \n",
      "\n",
      " 0.8414549487012356\n"
     ]
    }
   ],
   "source": [
    "print(gridsearch.best_estimator_,'\\n\\n',gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=10, max_features=8,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=50, n_jobs=1, oob_score=False, random_state=11,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=10, max_features=8, n_estimators=50, random_state=11)\n",
    "rfc.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[27632   802]\n",
      " [    4    43]] \n",
      "\n",
      "Area under PR curve:  0.8154126657937484 \n",
      "\n",
      "Accuracy:  0.9717004318668586\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_val)\n",
    "y_pred_probs = rfc.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features=8,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=12,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=5, max_features=8, n_estimators=100, random_state=12)\n",
    "rfc.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[26716  1718]\n",
      " [    3    44]] \n",
      "\n",
      "Area under PR curve:  0.845865292180593 \n",
      "\n",
      "Accuracy:  0.9395737509216671\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_val)\n",
    "y_pred_probs = rfc.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=5, max_features=8,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=13,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=5, max_features=8, n_estimators=20, random_state=13)\n",
    "rfc.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[26602  1832]\n",
      " [    4    43]] \n",
      "\n",
      "Area under PR curve:  0.723532641764517 \n",
      "\n",
      "Accuracy:  0.9355359713493206\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_val)\n",
    "y_pred_probs = rfc.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[26727  1701]\n",
      " [    2    51]] \n",
      "\n",
      "Area under PR curve:  0.7236615717937276 \n",
      "\n",
      "Accuracy:  0.9402057512025561\n"
     ]
    }
   ],
   "source": [
    "# predictions on the test set\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', max_depth=5, max_features=8, n_estimators=100, random_state=12)\n",
    "rfc.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_pred_probs = rfc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_test, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final Random Forest Classifier (with parameter set {'class_weight':'balanced', 'max_depth':5, 'max_features':8, 'n_estimators':100}) correctly detects 51/53 of the fraudulent transactions. However it manages to mistake around 6% of the non-fraudulent transactions as fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28329   105]\n",
      " [    4    43]] \n",
      "\n",
      "Area under PR curve:  0.7363794062480453 \n",
      "\n",
      "Accuracy:  0.9961728871879498\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_val)\n",
    "y_pred_probs = knn.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "knn.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28310   124]\n",
      " [    4    43]] \n",
      "\n",
      "Area under PR curve:  0.7643615252701048 \n",
      "\n",
      "Accuracy:  0.9955057757803448\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_val)\n",
    "y_pred_probs = knn.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_bal, y_train_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28300   134]\n",
      " [    4    43]] \n",
      "\n",
      "Area under PR curve:  0.7883584869356807 \n",
      "\n",
      "Accuracy:  0.9951546645131842\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_val)\n",
    "y_pred_probs = knn.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28331    97]\n",
      " [    9    44]] \n",
      "\n",
      "Area under PR curve:  0.7044731636558972 \n",
      "\n",
      "Accuracy:  0.996278220568098\n"
     ]
    }
   ],
   "source": [
    "# predictions on the test set\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_probs = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_test, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final k-Nearest Neighbors Classifier (with the default Scikit Learn parameter set) correctly detects 44/53 of the fraudulent transactions. However it manages to mistake around 0.3% of the non-fraudulent transactions as fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network-based Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Software\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 4,282\n",
      "Trainable params: 4,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "250232/250232 - 12s - loss: 0.2534 - acc: 0.9554\n",
      "Epoch 2/10\n",
      "250232/250232 - 11s - loss: 0.1083 - acc: 0.9824\n",
      "Epoch 3/10\n",
      "250232/250232 - 11s - loss: 0.0853 - acc: 0.9863\n",
      "Epoch 4/10\n",
      "250232/250232 - 12s - loss: 0.0712 - acc: 0.9883\n",
      "Epoch 5/10\n",
      "250232/250232 - 11s - loss: 0.0650 - acc: 0.9896\n",
      "Epoch 6/10\n",
      "250232/250232 - 11s - loss: 0.0573 - acc: 0.9907\n",
      "Epoch 7/10\n",
      "250232/250232 - 12s - loss: 0.0537 - acc: 0.9914\n",
      "Epoch 8/10\n",
      "250232/250232 - 11s - loss: 0.0503 - acc: 0.9918\n",
      "Epoch 9/10\n",
      "250232/250232 - 11s - loss: 0.0461 - acc: 0.9924\n",
      "Epoch 10/10\n",
      "250232/250232 - 11s - loss: 0.0437 - acc: 0.9926\n"
     ]
    }
   ],
   "source": [
    "# creating the network structure\n",
    "\n",
    "hidden_layer_size = [64,32,8]\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        \n",
    "    tf.keras.layers.Dense(hidden_layer_size[0], activation='relu', input_shape=(X_train_bal.shape[1],)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[2], activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "# checking model structure and no. of parameters\n",
    "\n",
    "model.summary()\n",
    "\n",
    "cls_wt = {0: 1, 1: 10}\n",
    "\n",
    "#compiling and fitting the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_bal, y_train_bal, epochs=10, class_weight=cls_wt, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28272   162]\n",
      " [    5    42]] \n",
      "\n",
      "Area under PR curve:  0.7724966620197126 \n",
      "\n",
      "Accuracy:  0.9941364418384186\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "y_pred_probs = model.predict(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 4,282\n",
      "Trainable params: 4,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "250232/250232 - 12s - loss: 0.2452 - acc: 0.9564\n",
      "Epoch 2/10\n",
      "250232/250232 - 12s - loss: 0.0991 - acc: 0.9825\n",
      "Epoch 3/10\n",
      "250232/250232 - 11s - loss: 0.0758 - acc: 0.9867\n",
      "Epoch 4/10\n",
      "250232/250232 - 11s - loss: 0.0623 - acc: 0.9888\n",
      "Epoch 5/10\n",
      "250232/250232 - 11s - loss: 0.0555 - acc: 0.9904\n",
      "Epoch 6/10\n",
      "250232/250232 - 11s - loss: 0.0512 - acc: 0.9909\n",
      "Epoch 7/10\n",
      "250232/250232 - 12s - loss: 0.0455 - acc: 0.9921\n",
      "Epoch 8/10\n",
      "250232/250232 - 11s - loss: 0.0424 - acc: 0.9925\n",
      "Epoch 9/10\n",
      "250232/250232 - 11s - loss: 0.0416 - acc: 0.9926\n",
      "Epoch 10/10\n",
      "250232/250232 - 11s - loss: 0.0385 - acc: 0.9932\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = [64,32,8]\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        \n",
    "    tf.keras.layers.Dense(hidden_layer_size[0], activation='relu', input_shape=(X_train_bal.shape[1],)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[2], activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "cls_wt = {0: 1, 1: 8}\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_bal, y_train_bal, epochs=10, class_weight=cls_wt, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28089   345]\n",
      " [    5    42]] \n",
      "\n",
      "Area under PR curve:  0.6947990897050854 \n",
      "\n",
      "Accuracy:  0.9877111056493802\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "y_pred_probs = model.predict(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 50)                1500      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 25)                1900      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 208       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 16,301\n",
      "Trainable params: 16,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "250232/250232 - 23s - loss: 0.2855 - acc: 0.9486\n",
      "Epoch 2/10\n",
      "250232/250232 - 23s - loss: 0.1328 - acc: 0.9786\n",
      "Epoch 3/10\n",
      "250232/250232 - 23s - loss: 0.1067 - acc: 0.9834\n",
      "Epoch 4/10\n",
      "250232/250232 - 23s - loss: 0.0902 - acc: 0.9857\n",
      "Epoch 5/10\n",
      "250232/250232 - 23s - loss: 0.0817 - acc: 0.9878\n",
      "Epoch 6/10\n",
      "250232/250232 - 24s - loss: 0.0765 - acc: 0.9883\n",
      "Epoch 7/10\n",
      "250232/250232 - 23s - loss: 0.0708 - acc: 0.9891\n",
      "Epoch 8/10\n",
      "250232/250232 - 23s - loss: 0.0671 - acc: 0.9898\n",
      "Epoch 9/10\n",
      "250232/250232 - 23s - loss: 0.0639 - acc: 0.9907\n",
      "Epoch 10/10\n",
      "250232/250232 - 23s - loss: 0.0605 - acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = [50,100,75,25,8]\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        \n",
    "    tf.keras.layers.Dense(hidden_layer_size[0], activation='relu', input_shape=(X_train_bal.shape[1],)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[1], activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[2], activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[3], activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[4], activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "cls_wt = {0: 1, 1: 10}\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_bal, y_train_bal, epochs=10, class_weight=cls_wt, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28179   255]\n",
      " [    5    42]] \n",
      "\n",
      "Area under PR curve:  0.6092607736354932 \n",
      "\n",
      "Accuracy:  0.9908711070538253\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "y_pred_probs = model.predict(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 4,282\n",
      "Trainable params: 4,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "250232/250232 - 12s - loss: 0.2902 - acc: 0.9469\n",
      "Epoch 2/15\n",
      "250232/250232 - 12s - loss: 0.1166 - acc: 0.9812\n",
      "Epoch 3/15\n",
      "250232/250232 - 12s - loss: 0.0884 - acc: 0.9859\n",
      "Epoch 4/15\n",
      "250232/250232 - 12s - loss: 0.0775 - acc: 0.9879\n",
      "Epoch 5/15\n",
      "250232/250232 - 12s - loss: 0.0667 - acc: 0.9892\n",
      "Epoch 6/15\n",
      "250232/250232 - 12s - loss: 0.0643 - acc: 0.9901\n",
      "Epoch 7/15\n",
      "250232/250232 - 12s - loss: 0.0573 - acc: 0.9914\n",
      "Epoch 8/15\n",
      "250232/250232 - 12s - loss: 0.0554 - acc: 0.9918\n",
      "Epoch 9/15\n",
      "250232/250232 - 12s - loss: 0.0484 - acc: 0.9925\n",
      "Epoch 10/15\n",
      "250232/250232 - 12s - loss: 0.0473 - acc: 0.9926\n",
      "Epoch 11/15\n",
      "250232/250232 - 12s - loss: 0.0445 - acc: 0.9931\n",
      "Epoch 12/15\n",
      "250232/250232 - 12s - loss: 0.0427 - acc: 0.9931\n",
      "Epoch 13/15\n",
      "250232/250232 - 12s - loss: 0.0406 - acc: 0.9935\n",
      "Epoch 14/15\n",
      "250232/250232 - 12s - loss: 0.0391 - acc: 0.9937\n",
      "Epoch 15/15\n",
      "250232/250232 - 12s - loss: 0.0374 - acc: 0.9938\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = [64,32,8]\n",
    "output_size = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        \n",
    "    tf.keras.layers.Dense(hidden_layer_size[0], activation='relu', input_shape=(X_train_bal.shape[1],)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size[2], activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "cls_wt = {0: 1, 1: 12}\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_bal, y_train_bal, epochs=15, class_weight=cls_wt, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[28286   148]\n",
      " [    5    42]] \n",
      "\n",
      "Area under PR curve:  0.5053338301685529 \n",
      "\n",
      "Accuracy:  0.9946279976124434\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "y_pred_probs = model.predict(X_val)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_val, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_val, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since neural networks are stochastic in nature, the results vary with every run. The model yielding best results was saved, and its performance on the test set is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Software\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Software\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Confusion Matrix: \n",
      " [[28066   362]\n",
      " [    8    45]] \n",
      "\n",
      "Area under PR curve:  0.7778394349088651 \n",
      "\n",
      "Accuracy:  0.9870088831150592\n"
     ]
    }
   ],
   "source": [
    "# predictions on the test set\n",
    "\n",
    "model = tf.keras.models.load_model('.../CreditCardFraud_NN.h5')\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred_probs = model.predict(X_test)[:, 1]\n",
    "\n",
    "cnf_mt = confusion_matrix(y_test, y_pred)\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_pred_probs)\n",
    "auc_pr = auc(rec, prec)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n',cnf_mt,'\\n\\nArea under PR curve: ', auc_pr, '\\n\\nAccuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final Neural Network-based Classifier (saved as 'CreditCardFraud_NN.h5') correctly detects 45/53 of the fraudulent transactions. However it manages to mistake around 1% of the non-fraudulent transactions as fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data provided, all the three models detected more than 80% of the fraudulent transactions.\n",
    "\n",
    "While the Random Forest Classifier manages to detect more than 95% of the fraudulent transactions, but it also misclassifies many proper transactions as fraudulent. The other two models do not do that well in detecting fraudulent transactions, but they have a significantly low misclassification rate. \n",
    "\n",
    "In this case, the bank can decide which model would suit them better. On a personal note, I would prefer the Random Forest Classifier. The transactions misclassified as fraudulent can be verified to be correct by the transaction initiator, and it is necessary to verify suspicious transactions even though it may cause minor inconvenience to the client."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
